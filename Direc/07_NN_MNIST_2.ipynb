{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorflow를 이용한 MNIST 실습 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 핵심은 정확도 비교해보기!\n",
    "#### 1) non-linearity 바꿔보기 : sigmoid -> relu\n",
    "#### 2) weight 초기화 바꿔보기: random -> xavier, he"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = input_data.read_data_sets('data/mnist/', one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'mnist' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-1aa29a200a4b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmnist\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmnist\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'mnist' is not defined"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR! Session/line number was not unique in database. History logging moved to new session 171\n"
     ]
    }
   ],
   "source": [
    "mnist.train, mnist.test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.float32)\n",
    "y = tf.placeholder(tf.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "neural networks 구축  \n",
    "1) weight 초기화 바꿔보기  \n",
    "2) non-linearity 바꿔보기"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "W_1 = tf.Variable(tf.random_normal([784, 128]))\n",
    "b_1 = tf.Variable(tf.random_normal([128]))\n",
    "hidden_1 = tf.sigmoid(tf.matmul(X, W_1) + b_1)\n",
    "\n",
    "W_2 = tf.Variable(tf.random_normal([128, 10]))\n",
    "b_2 = tf.Variable(tf.random_normal([10]))\n",
    "hypo = tf.sigmoid(tf.matmul(hidden_1, W_2) + b_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "W_1 = tf.get_variable(\"w1\", shape=[784, 128],\n",
    "                     initializer=tf.contrib.layers.xavier_initializer())\n",
    "b_1 = tf.get_variable(\"b1\", shape=[128], \n",
    "                     initializer=tf.contrib.layers.xavier_initializer())\n",
    "hidden_1  = tf.nn.relu(tf.matmul(X, W_1) + b_1)\n",
    "\n",
    "W_2 = tf.get_variable(\"w3\", shape=[128, 10],\n",
    "                     initializer=tf.contrib.layers.xavier_initializer())\n",
    "b_2 =  tf.get_variable(\"b3\", shape=[10], \n",
    "                     initializer=tf.contrib.layers.xavier_initializer())\n",
    "hypo = tf.matmul(hidden_1 , W_2) + b_2"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 초기화와 non-linearity의 상관관계\n",
    "1) sigmoid = xavier  \n",
    "2) relu = he : tf.contrib.layers.variance_scaling_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "cost = tf.reduce_mean(\n",
    "    tf.nn.softmax_cross_entropy_with_logits(\n",
    "        logits=hypo, labels=y))\n",
    "learning_rate = 0.1\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "cost = tf.reduce_mean(\n",
    "    tf.nn.softmax_cross_entropy_with_logits(\n",
    "        logits=hypo, labels=tf.stop_gradient(y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict = tf.cast(hypo > 0.5, tf.float32) # 1 or 0\n",
    "acc = tf.reduce_mean(tf.cast(tf.equal(predict, y), tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 100\n",
    "epoches = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total_batch :  550\n",
      " 1 : 0.24340792115100385\n",
      " 2 : 0.052112699679353024\n",
      " 3 : 0.032282024928453286\n",
      " 4 : 0.02396197996271604\n",
      " 5 : 0.01868721660268915\n",
      " 6 : 0.014412688048217768\n",
      " 7 : 0.011446066415149036\n",
      " 8 : 0.010679033734539357\n",
      " 9 : 0.00826593230160969\n",
      "10 : 0.007479154927952384\n",
      "Learning finished!\n",
      "accuracy : 0.971\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    # total_batch 수(업데이트 수) = 전체 데이터 개수 // batch크기\n",
    "    total_batch = mnist.train.num_examples//batch_size\n",
    "    print('total_batch : ', total_batch)\n",
    "\n",
    "    for epoch in range(epoches):\n",
    "        avg_cost = 0\n",
    "\n",
    "        for i in range(total_batch):\n",
    "            #training dataset\n",
    "            batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "\n",
    "\n",
    "            sess.run(optimizer, \n",
    "                     feed_dict={X: batch_xs, y: batch_ys})\n",
    "            c = sess.run(cost\n",
    "                         , feed_dict={X: batch_xs, y: batch_ys})\n",
    "\n",
    "            avg_cost += c / total_batch\n",
    "\n",
    "        print('{:2} : {:}'.format(epoch+1, avg_cost))\n",
    "    print('Learning finished!')\n",
    "    \n",
    "    pred = tf.equal(tf.argmax(hypo, 1), tf.argmax(y, 1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(pred, tf.float32))\n",
    "\n",
    "    print('accuracy :', sess.run(accuracy, feed_dict={X: mnist.test.images, \n",
    "                                                  y: mnist.test.labels}))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
