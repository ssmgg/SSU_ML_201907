{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorflow를 이용한 MNIST 실습 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 핵심은 정확도 비교해보기!\n",
    "#### 1) hidden layer 개수를 조절하면서\n",
    "#### 2) layer 의 node 개수를 조절하면서\n",
    "#### 3) epoch의 수를 조절하면서"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tensor graph reset 함수\n",
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mnist = input_data.read_data_sets('data/mnist/', one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'mnist' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-1aa29a200a4b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmnist\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmnist\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'mnist' is not defined"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR! Session/line number was not unique in database. History logging moved to new session 169\n"
     ]
    }
   ],
   "source": [
    "mnist.train, mnist.test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.float32)\n",
    "y = tf.placeholder(tf.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "neural networks 구축  \n",
    "1) layer 수 조절해보기  \n",
    "2) layer 마다의 node 수 조절해보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "W_1 = tf.Variable(tf.random_normal([784, 256]))\n",
    "b_1 = tf.Variable(tf.random_normal([256]))\n",
    "h_1 = tf.sigmoid(tf.matmul(X, W_1) + b_1)\n",
    "\n",
    "W_2 = tf.Variable(tf.random_normal([256, 10]))\n",
    "b_2 = tf.Variable(tf.random_normal([10]))\n",
    "hypo = tf.sigmoid(tf.matmul(h_1, W_2) + b_2)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "W_1 = tf.Variable(tf.random_normal([784, 128]))\n",
    "b_1 = tf.Variable(tf.random_normal([128]))\n",
    "hidden_1 = tf.sigmoid(tf.matmul(X, W_1) + b_1)\n",
    "\n",
    "W_2 = tf.Variable(tf.random_normal([128, 64]))\n",
    "b_2 = tf.Variable(tf.random_normal([64]))\n",
    "hidden_2 = tf.sigmoid(tf.matmul(hidden_1, W_2) + b_2)\n",
    "\n",
    "W_3 = tf.Variable(tf.random_normal([64, 10]))\n",
    "b_3 = tf.Variable(tf.random_normal([10]))\n",
    "hypo = tf.sigmoid(tf.matmul(hidden_2, W_3) + b_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "cost = tf.reduce_mean(\n",
    "    tf.nn.softmax_cross_entropy_with_logits(\n",
    "        logits=hypo, labels=y))\n",
    "#우리가 이미 살펴봤던 loss(logits=예측값, labels=실제값)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "predict : hypo > 0.5 크다면 1로 저장.  \n",
    "hypo > 0.5 -> 논리식이기 때문에, 결과값이 True or False  \n",
    "tf.cast(\"value\", \"변환할 type\")\n",
    ": value를 해당 type으로 형변환 : True -> 1, False -> 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "accuracy  \n",
    "tf.equal(predict, y) : predict와 y 과 같니? -> 같으면 True, 다르면 False  \n",
    "tf.cast : 1, 0 (array로 저장)\n",
    "tf.reduce_mean : array 평균 : 전체중에 1이 몇 %있니?  \n",
    "ex) [1, 1, 1, 1, 0] : 0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict = tf.cast(hypo > 0.5, tf.float32) # 1 or 0\n",
    "accuracy = tf.reduce_mean(tf.cast(tf.equal(predict, y), tf.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3) epoch 수를 조절해보세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 100\n",
    "epoches = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total_batch :  550\n",
      " 1 : 1.8867872710661477\n",
      " 2 : 1.6676438238404\n",
      " 3 : 1.621898594552818\n",
      " 4 : 1.5981554096395305\n",
      " 5 : 1.5827815903316833\n",
      " 6 : 1.5719817410815846\n",
      " 7 : 1.5635487924922595\n",
      " 8 : 1.5569464312900219\n",
      " 9 : 1.5513458568399603\n",
      "10 : 1.546677869233219\n",
      "Learning finished!\n",
      "accuracy : 0.97172\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    # total_batch 수(업데이트 수) = 전체 데이터 개수 // batch크기\n",
    "    total_batch = mnist.train.num_examples//batch_size\n",
    "    print('total_batch : ', total_batch)\n",
    "\n",
    "    for epoch in range(epoches):\n",
    "        avg_cost = 0\n",
    "\n",
    "        for i in range(total_batch):\n",
    "            #training dataset\n",
    "            batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "\n",
    "\n",
    "            sess.run(optimizer, \n",
    "                     feed_dict={X: batch_xs, y: batch_ys})\n",
    "            c = sess.run(cost\n",
    "                         , feed_dict={X: batch_xs, y: batch_ys})\n",
    "\n",
    "            avg_cost += c / total_batch\n",
    "\n",
    "        print('{:2} : {:}'.format(epoch+1, avg_cost))\n",
    "    print('Learning finished!')\n",
    "\n",
    "    print('accuracy :', sess.run(accuracy, feed_dict={X: mnist.test.images, \n",
    "                                                  y: mnist.test.labels}))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
